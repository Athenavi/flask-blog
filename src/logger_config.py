# logger_config.py
import json
import logging
import os
import shutil
from datetime import datetime, timezone
from logging.handlers import RotatingFileHandler

from prometheus_client import start_http_server, Counter, Gauge

# åˆå§‹åŒ–å…¨å±€æŒ‡æ ‡
REQUEST_COUNT = Counter('app_requests_total', 'Total application requests')
ERROR_COUNT = Counter('app_errors_total', 'Total application errors')
LATENCY_GAUGE = Gauge('app_request_latency_seconds', 'Application request latency')
MEMORY_USAGE = Gauge('app_memory_usage_mb', 'Application memory usage in MB')
CPU_USAGE = Gauge('app_cpu_usage_percent', 'Application CPU usage percent')


class StructuredFormatter(logging.Formatter):
    """ç»“æ„åŒ–æ—¥å¿—æ ¼å¼åŒ–å™¨ (JSONæ ¼å¼)"""

    MAX_MSG_SIZE = 32 * 1024  # 32KBæœ€å¤§æ¶ˆæ¯é•¿åº¦

    def format(self, record):
        # æˆªæ–­è¶…å¤§æ¶ˆæ¯
        msg = record.getMessage()
        if len(msg) > self.MAX_MSG_SIZE:
            record.msg = msg[:self.MAX_MSG_SIZE] + "...[TRUNCATED]"

        log_data = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'level': record.levelname,
            'message': record.getMessage(),
            'logger': record.name,
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
            'thread': record.threadName,
            'process': record.processName
        }

        # æ·»åŠ ä¸šåŠ¡æŒ‡æ ‡
        if hasattr(record, 'metrics'):
            log_data.update(record.metrics)

        return json.dumps(log_data)


class AlertHandler(logging.Handler):
    """è‡ªå®šä¹‰å‘Šè­¦å¤„ç†å™¨"""

    def __init__(self, alert_threshold=logging.ERROR, alert_callback=None):
        super().__init__()
        self.alert_threshold = alert_threshold
        self.alert_callback = alert_callback or self.default_alert_callback

    def emit(self, record):
        if record.levelno >= self.alert_threshold:
            alert_data = {
                'level': record.levelname,
                'message': record.getMessage(),
                'time': datetime.now(timezone.utc).isoformat(),
                'location': f"{record.module}.{record.funcName}:{record.lineno}"
            }
            self.alert_callback(alert_data)

    @staticmethod
    def default_alert_callback(alert_data):
        """é»˜è®¤å‘Šè­¦å¤„ç†ï¼ˆæ‰“å°åˆ°æ§åˆ¶å°ï¼‰"""
        print(f"ğŸš¨ ALERT TRIGGERED: {alert_data}")


def check_disk_space(log_dir, threshold_mb=100):
    """æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³"""
    try:
        total, used, free = shutil.disk_usage(log_dir)
        free_space_mb = free / (1024 * 1024)  # è½¬æ¢ä¸ºMB
        if free_space_mb < threshold_mb:
            return False, free_space_mb
        return True, free_space_mb
    except Exception as e:
        logging.error(f"ç£ç›˜ç©ºé—´æ£€æŸ¥å¤±è´¥: {str(e)}")
        return False, 0


def init_logger(
        log_dir="logs",
        log_base_name="app",
        max_bytes=10 * 1024 * 1024,  # 10MB
        backup_count=5,
        log_level=logging.INFO,
        metrics_port=9090,
        enable_metrics=True
):
    """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ

    å‚æ•°:
      log_dir: æ—¥å¿—æ–‡ä»¶å­˜æ”¾ç›®å½•
      log_base_name: æ—¥å¿—æ–‡ä»¶åŸºç¡€åç§°
      max_bytes: å•ä¸ªæ—¥å¿—æ–‡ä»¶çš„æœ€å¤§å­—èŠ‚æ•°
      backup_count: ä¿ç•™å¤‡ä»½æ–‡ä»¶çš„æ•°é‡
      log_level: æ—¥å¿—çº§åˆ«
      metrics_port: PrometheusæŒ‡æ ‡æš´éœ²ç«¯å£
      enable_metrics: æ˜¯å¦å¯ç”¨æŒ‡æ ‡ç›‘æ§
    """
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(log_dir, exist_ok=True)

    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    has_space, free_space = check_disk_space(log_dir)
    if not has_space:
        raise RuntimeError(f"Insufficient disk space: {free_space:.2f}MB left in {log_dir}")

    # å¯åŠ¨PrometheusæŒ‡æ ‡æœåŠ¡å™¨
    if enable_metrics:
        start_http_server(metrics_port)
        print(f"ğŸ“Š Metrics server started on port {metrics_port}")

    # è·å–æ ¹æ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger()
    logger.setLevel(log_level)

    # åˆ›å»ºç»“æ„åŒ–æ—¥å¿—æ ¼å¼å™¨
    structured_formatter = StructuredFormatter()

    # ä½¿ç”¨å›ºå®šæ–‡ä»¶åä¿è¯è½®è½¬ç”Ÿæ•ˆ
    log_path = os.path.join(log_dir, f"{log_base_name}.log")

    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = RotatingFileHandler(
        log_path,
        maxBytes=max_bytes,
        backupCount=backup_count,
        encoding='utf-8'
    )
    file_handler.setFormatter(structured_formatter)
    logger.addHandler(file_handler)

    # è®¾ç½®æ–‡ä»¶æƒé™ (644)
    try:
        os.chmod(log_path, 0o644)
    except Exception as e:
        logger.warning(f"Failed to set log file permissions: {str(e)}")

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_formatter = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(module)s:%(funcName)s:%(lineno)d - %(message)s'
    )
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    # å‘Šè­¦å¤„ç†å™¨
    alert_handler = AlertHandler(
        alert_threshold=logging.ERROR,
        alert_callback=lambda alert: logger.critical(f"ALERT: {alert}")
    )
    logger.addHandler(alert_handler)

    logger.info("âœ… Logger initialized", extra={
        'metrics': {
            'log_file': log_path,
            'log_level': logging.getLevelName(log_level),
            'max_size_mb': max_bytes // (1024 * 1024),
            'backup_count': backup_count,
            'free_space_mb': free_space
        }
    })

    return logger


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    logger = init_logger()

    # æµ‹è¯•æ—¥å¿—
    logger.debug("Debug message")
    logger.info("Info message")
    logger.warning("Warning message")
    try:
        1 / 0
    except Exception as e:
        logger.error("Error occurred", exc_info=True)

    # æµ‹è¯•å¤§æ—¥å¿—æ¶ˆæ¯
    large_msg = "A" * 50 * 1024  # 50KB
    logger.info(f"Large message test: {large_msg}")
